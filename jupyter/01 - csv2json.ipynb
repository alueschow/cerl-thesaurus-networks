{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee21ad6e",
   "metadata": {},
   "source": [
    "# Tutorial: CSV2JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186bb917",
   "metadata": {},
   "source": [
    "The _CSV2JSON_ class is used to transform metadata from a CSV to JSON format that can be used in further analysis.\n",
    "\n",
    "Author: Andreas Lüschow\n",
    "\n",
    "Last updated: 2021/07/28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadef6b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2969d58",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64cf0b",
   "metadata": {},
   "source": [
    "Import the appropriate class from __Bibliometa__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64008c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bibliometa.conversion import CSV2JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740aba98",
   "metadata": {},
   "source": [
    "As you can see from the following output, the _CSV2JSON_ class has a lot of built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e38187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_save_results',\n",
       " '_update_config',\n",
       " 'get_config',\n",
       " 'set_config',\n",
       " 'start']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(CSV2JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de11396",
   "metadata": {},
   "source": [
    "We are only interested in the public methods, so let's have a look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9447c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get_config', 'set_config', 'start']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(CSV2JSON) if not m.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eef2da",
   "metadata": {},
   "source": [
    "The usage of _CSV2JSON_ class is quite simple: There are two methods to work with the class configuration, and only one method to actually start the conversion process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad0fd0",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238e97a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34fef8",
   "metadata": {},
   "source": [
    "Most __Bibliometa__ classes come with already predefined configuration for their class attributes. In this case, you can see the default configuration using the _get_config()_ function on a new _CSV2JSON_ object. So let's create an object first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57706b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2j = CSV2JSON()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33defb6",
   "metadata": {},
   "source": [
    "### Input, output, year range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509a551",
   "metadata": {},
   "source": [
    "And now let's have a look at the default configuration values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abb1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', None)\n",
       "('o', None)\n",
       "('from_', None)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc08ac5",
   "metadata": {},
   "source": [
    "As a shortcut, you can also simply print out the object itself which will return a representation of the configuration values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54e4977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', None)\n",
       "('o', None)\n",
       "('from_', None)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c06fa",
   "metadata": {},
   "source": [
    "There are a lot of configuration options, let's go through them step by step.\n",
    "\n",
    "__i__ (str): Input CSV file\n",
    "* Path to the CSV file that will be converted.\n",
    "\n",
    "__o__ (str): Output JSON file\n",
    "* Path to the JSON file that will be created. If the path contains folders that are not existent yet, they will be created during the conversion process.\n",
    "\n",
    "**from_** (int): Year where conversion starts\n",
    "* Data from the input file are processed year by year. Only those data sets that are within a certain interval are considered in the conversion process. The _from__ parameter (mind the trailing underscore!) is used to define the \"starting year\", i.e., the \"oldest\" year that is respected in the conversion process.\n",
    "\n",
    "__to__ (int): Year where conversion ends\n",
    "* This is the last year that is considered in the conversion process.\n",
    "\n",
    "__step__ (int): Interval between two years\n",
    "* Using this parameter you can define how many \"year slices\" the conversion will produce. For example, let's assume that *from_* == 1750 and _to_ == 1850. Setting the parameter _step_ to 10 would create a JSON file for 1750, 1760, 1770, ... up to 1850 each. Setting _step_ to 25 would create JSON files for 1750, 1775, 1800, ... up to 1850. If you need only one single year, you have to set both *from_* and _to_ to the same year, _step_ will have no effect then. However, the parameter _step_ has to be always greater than zero; otherwise an error will be thrown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded6e7a",
   "metadata": {},
   "source": [
    "At this point, let's try to change a configuration parameter using the _set_config()_ function. After each function call the current configuration is printed out automatically to check if your changes worked as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e874e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', None)\n",
       "('o', None)\n",
       "('from_', 500)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.set_config(from_=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3917d54",
   "metadata": {},
   "source": [
    "Calling the _set_config()_ function with keyword arguments allows you to change the configuration parameters according to your needs. Since it is a bit cumbersome to find the parameters in the output above, you can also use keyword arguments with the _get_config()_ function to check for specific configuration parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6336ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('from_', 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config(\"from_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195c1cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('from_', 500)\n",
       "('to', None)\n",
       "('step', 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config(\"from_\", \"to\", \"step\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c10088",
   "metadata": {},
   "source": [
    "As you can see, working with configuration parameters is quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3881439f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35918f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', '../data/my_own_data.csv')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.set_config(i=\"../data/my_own_data.csv\")\n",
    "c2j.get_config(\"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d3ed6",
   "metadata": {},
   "source": [
    "Actually, if you know the parameter you want to change, you can also set and get configuration parameters using a dot notation. This is the preferred way if you need to change or access only a single parameter value, since the output does not include the parameter key itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d327e20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/my_very_own_data.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.config.i = \"../data/my_very_own_data.csv\"\n",
    "c2j.config.i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdc6c3",
   "metadata": {},
   "source": [
    "However, if you need to change or access more than one configuration parameter, using the _set_config()_ and _get_config()_ functions is the way to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90125d92",
   "metadata": {},
   "source": [
    "### Field definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e13d7",
   "metadata": {},
   "source": [
    "Bur for now let's go back to explaining the remaining configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ed11ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', '../data/my_very_own_data.csv')\n",
       "('o', None)\n",
       "('from_', 500)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91641b12",
   "metadata": {},
   "source": [
    "__fields__ (list of dict): Fields and subfields to consider\n",
    "* This parameter defines which columns from the input data will be converted to JSON. Each field/subfield combination needs to be represented in a single dictionary with the keys _content_, _type_, and _categories_:\n",
    "\n",
    "    `{'content': ('515', 'a'),\n",
    "    'type': ('515', '0'),\n",
    "    'categories': ['actv']}`\n",
    "    \n",
    "    These three keys need to have a unique representation in the input CSV. In the example above, this means that we need a column containing values from field 515, subfield a, another column with values from field 515, subfield 0, and that content in field 515, subfield 0, has to be identical to a value from the \"categories\" list to be considered for conversion.\n",
    "    \n",
    "__subfield_sep__ (str): Separator between fields and subfields\n",
    "* This separator is used to combine field and subfield values to a single string. For example, if your input CSV contains columns such as \"515\\\\$a\" and \"515\\\\$0\", the dollar sign \\\\$ is your subfield separator.\n",
    "\n",
    "__split_char__ (str): Character between values in cells\n",
    "* This/These character(s) is/are used to distinguish different values in the same CSV cell. \n",
    "\n",
    "__csv_sep__ (str): CSV separator\n",
    "* The seperator that is used between single CSV fields (usually something like \"\\t\" or \",\" or \";\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916de3f8",
   "metadata": {},
   "source": [
    "To understand the explanations above let's have a look into the example input CSV file that comes with the tutorial (using standard python code and the pandas library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f95ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>515$a</th>\n",
       "      <th>515$0</th>\n",
       "      <th>515$z</th>\n",
       "      <th>350$0</th>\n",
       "      <th>350$a</th>\n",
       "      <th>340$x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnp01448516</td>\n",
       "      <td>Laynborgh ### Ewald ### de ###</td>\n",
       "      <td>Schillingen ###</td>\n",
       "      <td>actv ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acti ###</td>\n",
       "      <td>Pastor ###</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnp01449196</td>\n",
       "      <td>Rijfrock de Grymalscheit ### Johann ###</td>\n",
       "      <td>Wijs ###</td>\n",
       "      <td>actv ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acti ###</td>\n",
       "      <td>Pfarrer ###</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnp01449439</td>\n",
       "      <td>Sauerborn ### Ludwig ###</td>\n",
       "      <td>Koblenz ###</td>\n",
       "      <td>actv ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnp01448445</td>\n",
       "      <td>Nikolaus ###</td>\n",
       "      <td>Ehrang ###</td>\n",
       "      <td>actv ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acti ###</td>\n",
       "      <td>Pastor ###</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnp01449826</td>\n",
       "      <td>Boppard ### Reinhard ### von ###</td>\n",
       "      <td>Mosbach ###</td>\n",
       "      <td>actv ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acti ###</td>\n",
       "      <td>Pfarrer ###</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      name             515$a  \\\n",
       "0  cnp01448516           Laynborgh ### Ewald ### de ###   Schillingen ###    \n",
       "1  cnp01449196  Rijfrock de Grymalscheit ### Johann ###          Wijs ###    \n",
       "2  cnp01449439                 Sauerborn ### Ludwig ###       Koblenz ###    \n",
       "3  cnp01448445                             Nikolaus ###        Ehrang ###    \n",
       "4  cnp01449826         Boppard ### Reinhard ### von ###       Mosbach ###    \n",
       "\n",
       "       515$0 515$z      350$0         350$a 340$x  \n",
       "0  actv ###    NaN  acti ###    Pastor ###    NaN  \n",
       "1  actv ###    NaN  acti ###   Pfarrer ###    NaN  \n",
       "2  actv ###    NaN        NaN           NaN   NaN  \n",
       "3  actv ###    NaN  acti ###    Pastor ###    NaN  \n",
       "4  actv ###    NaN  acti ###   Pfarrer ###    NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"../data/examples/demo.csv\"  # This will later be our input file (parameter \"i\")\n",
    "df = pd.read_csv(path, sep=\"\\t\")  # There's the CSV separator\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb5066",
   "metadata": {},
   "source": [
    "You can see nine columns:\n",
    "* index column of the Pandas DataFrame (which has no name)\n",
    "* id \n",
    "* name\n",
    "* 515\\\\$a (mind the dollar sign as subfield separator!)\n",
    "* 515\\\\$0\n",
    "* 515\\\\$z\n",
    "* 350\\\\$0\n",
    "* 350\\\\$a\n",
    "* 340\\\\$x\n",
    "\n",
    "You can also see that mutiple values in a cell are divided by the string \" ### \", which is our _split_char_ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ae23fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('split_char', ' ### ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config(\"split_char\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8f3aa",
   "metadata": {},
   "source": [
    "The _fields_ parameter in our configuration looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f3af8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config(\"fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbe7b7",
   "metadata": {},
   "source": [
    "Looking at the example CSV, this means that values in column \"515\\\\$a\" (\"content\") are considered during the conversion process only if the corresponding value in column \"515\\\\$0\" (\"type\") has the value \"actv\" (\"categories).\n",
    "\n",
    "The following row would thus be ignored (it contains only \"brth\" and \"deat\" values in column \"515\\\\$0\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b57ca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>515$a</th>\n",
       "      <th>515$0</th>\n",
       "      <th>515$z</th>\n",
       "      <th>350$0</th>\n",
       "      <th>350$a</th>\n",
       "      <th>340$x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnp01300387</td>\n",
       "      <td>Randon ### Claudius ###</td>\n",
       "      <td>Pontoise ### Rom ###</td>\n",
       "      <td>brth ### deat ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acti ###</td>\n",
       "      <td>Künstler ###</td>\n",
       "      <td>340 01$8ger$aum 1674 - nach 1704$xa1674a1704 ###</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                      name                  515$a  \\\n",
       "12  cnp01300387  Randon ### Claudius ###   Pontoise ### Rom ###    \n",
       "\n",
       "                 515$0 515$z      350$0          350$a  \\\n",
       "12  brth ### deat ###    NaN  acti ###   Künstler ###    \n",
       "\n",
       "                                                340$x  \n",
       "12  340 01$8ger$aum 1674 - nach 1704$xa1674a1704 ###   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"] == \"cnp01300387\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ccbc0",
   "metadata": {},
   "source": [
    "However, this row would be converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87085e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>515$a</th>\n",
       "      <th>515$0</th>\n",
       "      <th>515$z</th>\n",
       "      <th>350$0</th>\n",
       "      <th>350$a</th>\n",
       "      <th>340$x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cnp02161976</td>\n",
       "      <td>Vila ### Joan ### 1515?-1597</td>\n",
       "      <td>Barcelona ### Cervera ### Vic ###</td>\n",
       "      <td>actv ### actv ### deat ###</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acti ### prof ### prof ### prof ### prof ### p...</td>\n",
       "      <td>Teologia ### Bisbes ### Canonges ### Catedràti...</td>\n",
       "      <td>340 01$8cat$a1515?-1597$xa1515a1597 ###</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                          name  \\\n",
       "26  cnp02161976  Vila ### Joan ### 1515?-1597   \n",
       "\n",
       "                                 515$a                        515$0 515$z  \\\n",
       "26  Barcelona ### Cervera ### Vic ###   actv ### actv ### deat ###    NaN   \n",
       "\n",
       "                                                350$0  \\\n",
       "26  acti ### prof ### prof ### prof ### prof ### p...   \n",
       "\n",
       "                                                350$a  \\\n",
       "26  Teologia ### Bisbes ### Canonges ### Catedràti...   \n",
       "\n",
       "                                       340$x  \n",
       "26  340 01$8cat$a1515?-1597$xa1515a1597 ###   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"] == \"cnp02161976\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640acb8",
   "metadata": {},
   "source": [
    "To be more pecise, only the two values \"Barcelona\" and \"Cervera\" from column \"515\\\\$a\" would be considered in the conversion, since they are the only ones with a corresponding \"actv\" value in column \"515\\\\$0\".\n",
    "\n",
    "To be even more precise, this row from the CSV file would only be considered during conversion if a year between 1515 and 1597 is used in the conversion. How can we know? For this, we have to look at two other configuration parameters, _datefield_ and _date_indicator_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070dd5c",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d571e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', '../data/my_very_own_data.csv')\n",
       "('o', None)\n",
       "('from_', 500)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea3ccb",
   "metadata": {},
   "source": [
    "__datefield__ (tuple): Field and subfield of date information\n",
    "* The example configuration defines that information about dates for a single row can be found in column \"340\\\\$x\"\n",
    "\n",
    "__date_indicator__ (list of str): Indicators in datefield that are accepted\n",
    "* Two values are possible: \"0\" means that biographical dates are considered; \"1\" means that activity dates are considered.\n",
    "\n",
    "__interval_lower__ (int): Lower interval for single dates\n",
    "* This parameter defines up to which lower bound data sets from the input CSV are considered for conversion if there is only a single year value available in the date column (see below for an example).\n",
    "\n",
    "__interval_upper__ (int): Upper interval for single dates\n",
    "* See the explanation for the previous parameter; here, the upper bound is defined.\n",
    "\n",
    "You can see the date indicator at position 5 in the datefield column after the field number 340 and a space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06cdb4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5                        340 11$8ger$a12. Jahrhundert ### \n",
       "7                                   340 11$8ger$a1161 ### \n",
       "8                        340 11$8ger$a13. Jahrhundert ### \n",
       "11                 340 01$8cat$a1803-1883$xa1803a1883 ### \n",
       "12       340 01$8ger$aum 1674 - nach 1704$xa1674a1704 ### \n",
       "                               ...                        \n",
       "73638                   340 11$8ger$a1734$xa1734u     ### \n",
       "73639    340 01$8ger$a10.08.1775-14.11.1830$xa1775a1830...\n",
       "73640    340 01$8ger$a29.09.1803-10.04.1872$xa1803a1872...\n",
       "73641    340 01$8ger$a25.12.1821-09.05.1874$xa1821a1874...\n",
       "73642              340 01$8ger$a1487-1558$xa1487a1558 ### \n",
       "Name: 340$x, Length: 72915, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"340$x\"].notna()][\"340$x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f6bc0",
   "metadata": {},
   "source": [
    "You can also see the values of subfield \"\\\\$x\" For example, in row with ID 11 this subfield has the value \"a1803a1883\" which means that the person represented in this data set lived from 1803 to 1883. Hence, this row would only be considered during conversion if a year between 1803 and 1883 is used in the configuration. (Which would be the case if we would set *from_* == 1800 and _to_ == 1825, or *from_* == 1700 and _to_ == 1850, or even *from_* == 1883 and _to_ == 1884 etc.)\n",
    "\n",
    "In row with ID 73638, there is only one year in subfield \"\\\\$x\" available: 1734, which is the begin of an activity (because the date indicator is set to == 1 in this row). In these cases, the data set is only considered for conversion if \"1\" is given in parameter _datefield_ and if the value in subfield \"\\\\$x\" is within the interval defined by the current conversion year and the _intervall_lower_ and _interval_upper_ parameters.\n",
    "\n",
    "Row with ID 73638 would hence be considered in the following example cases:\n",
    "* *from_* == 1700, _to_ == 1800, _step_ == 1, _interval_lower_ == 0, _interval_upper_ == 0 (because _step_ == 1, which means that every single year between 1700 and 1800 in considered)\n",
    "* *from_* == 1700, _to_ == 1800, _step_ == 10,  _interval_lower_ == 5, _interval_upper_ == 5 (because 1734 is within the interval 1730 (+/-5 years))\n",
    "* *from_* == 1730, _to_ == 1740, _step_ == 2,  _interval_lower_ == 0, _interval_upper_ == 0 (because 1734 is already considered by using a _step_ == 2 from 1730 to 1740)\n",
    "* *from_* == 1700, _to_ == 1750, _step_ == 25,  _interval_lower_ == 0, _interval_upper_ == 10 (because 1734 is within the upper 10-year-range of year 1725)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1fd58",
   "metadata": {},
   "source": [
    "### Logging, encoding, verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324e84e",
   "metadata": {},
   "source": [
    "There are only a couple of configuration parameters left, let's have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4f2ef7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', '../data/my_very_own_data.csv')\n",
       "('o', None)\n",
       "('from_', 500)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c26267",
   "metadata": {},
   "source": [
    "__log__ (str): Path to log file\n",
    "* The conversion process and its errors are documented in a log file. If _verbose_ == True (see below), the logging information is also shown on standard output if its level is _log_level_std_ or above.\n",
    "\n",
    "__log_level_std__ (str): Logging level considered for standard output\n",
    "* Only log messages with this level (or above) are shown on the standard output. This parameter has no effect if _verbose_ == False. Possible severity levels can be found in the documentation of the logging package `loguru`: https://loguru.readthedocs.io/en/stable/api/logger.html\n",
    "\n",
    "__log_level_file__ (str): Logging level considered for log file\n",
    "* Only log messages with this level (or above) are shown in the log file.\n",
    "\n",
    "__verbose__ (bool): Show detailed information on standard output\n",
    "* Whether logging information is not only written to the log file but also shown on the standard output.\n",
    "\n",
    "__encoding__ (str): File encoding\n",
    "* File encoding of input and output files. The default value is \"utf-8\" and there is usually no need to change this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6741bfd",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3c253",
   "metadata": {},
   "source": [
    "## The Conversion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b57f9",
   "metadata": {},
   "source": [
    "Configuration parameters can already be passed when a _CSV2JSON_ object is constructed. For some classes in __Bibliometa__ this may be useful when a verbose output of the class initialization is desired. (However, in the case of the class _CSV2JSON_ there is nothing that can be shown, so passing the configuration parameters during initialization or afterwards makes no difference.)\n",
    "\n",
    "We start with creating a new _CSV2JSON_ object that has the standard configuration values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52d0baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', None)\n",
       "('o', None)\n",
       "('from_', None)\n",
       "('to', None)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}, {'content': ('350', 'a'), 'type': ('350', '0'), 'categories': ['acti']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['0', '1'])\n",
       "('interval_lower', 10)\n",
       "('interval_upper', 10)\n",
       "('log', None)\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j = CSV2JSON()\n",
    "c2j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d9873",
   "metadata": {},
   "source": [
    "In the next step we define our custom configuration parameters as Python constants for better code readability and maintenance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "759265f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"../data/examples/demo.csv\"\n",
    "OUTPUT_FILE = \"../data/output/json/demo.json\"\n",
    "LOGFILE=\"../data/logs/csv2json_demo.out\"\n",
    "YEARS = (1700, 1750)\n",
    "STEP = 10\n",
    "FIELDS = [\n",
    "    {\"content\": (\"515\", \"a\"),\n",
    "     \"type\": (\"515\", \"0\"),\n",
    "     \"categories\": [\"actv\"]}\n",
    "]\n",
    "DATE_INDICATOR = [\"1\"]  # i.e., only activity dates are considered\n",
    "DATEFIELD = (\"340\", \"x\")\n",
    "INTERVALS = (5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466acf3",
   "metadata": {},
   "source": [
    "Now we can update our _CSV2JSON_ object accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acab0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', '../data/examples/demo.csv')\n",
       "('o', '../data/output/json/demo.json')\n",
       "('from_', 1700)\n",
       "('to', 1750)\n",
       "('step', 10)\n",
       "('fields', [{'content': ('515', 'a'), 'type': ('515', '0'), 'categories': ['actv']}])\n",
       "('subfield_sep', '$')\n",
       "('split_char', ' ### ')\n",
       "('csv_sep', '\\t')\n",
       "('datefield', ('340', 'x'))\n",
       "('date_indicator', ['1'])\n",
       "('interval_lower', 5)\n",
       "('interval_upper', 5)\n",
       "('log', '../data/logs/csv2json_demo.out')\n",
       "('log_level_std', 'INFO')\n",
       "('log_level_file', 'DEBUG')\n",
       "('verbose', False)\n",
       "('encoding', 'utf-8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2j.set_config(i=INPUT_FILE,\n",
    "               o=OUTPUT_FILE,\n",
    "               log=LOGFILE,\n",
    "               from_=YEARS[0],\n",
    "               to=YEARS[1],\n",
    "               step=STEP,\n",
    "               fields=FIELDS,\n",
    "               date_indicator=DATE_INDICATOR,\n",
    "               datefield=DATEFIELD,\n",
    "               interval_lower=INTERVALS[0],\n",
    "               interval_upper=INTERVALS[1],\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6683ca5",
   "metadata": {},
   "source": [
    "Finally, we start the conversion process by calling the _start()_ function. This function does not take any parameters.\n",
    "\n",
    "A progress bar for each year will indicate the conversion progress. Since we have defined *from_* == 1700, _to_ == 1750 and _step_ == 10, we will get six progress bars (one for 1700, 1710, 1720, 1730, 1740, and 1750 each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7df0b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23250b7c086d40368d4af96f7cfba6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2e0b1996f34625a711ac092f225698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9746fbe0ac49849ecec7662a269a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de031ee785a440bb03a99799647a7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbaf5d4d374452eac287e5e4e8f40bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa01d6794273426491aef767555a1f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c2j.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f31603",
   "metadata": {},
   "source": [
    "Let's have a look at the produced files, starting with the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "284356d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-07-28T15:39:23.667319+0200 INFO Start conversion from CSV to JSON.',\n",
       " '2021-07-28T15:39:24.373324+0200 INFO Size of import data: 73644 data sets',\n",
       " '2021-07-28T15:39:35.424939+0200 INFO Size of output data for year 1700 (+5/-5 years): 1164 data sets (1.58 %) ',\n",
       " '2021-07-28T15:39:46.224414+0200 INFO Size of output data for year 1710 (+5/-5 years): 1293 data sets (1.76 %) ',\n",
       " '2021-07-28T15:39:57.036569+0200 INFO Size of output data for year 1720 (+5/-5 years): 1320 data sets (1.79 %) ',\n",
       " '2021-07-28T15:40:07.707243+0200 INFO Size of output data for year 1730 (+5/-5 years): 1244 data sets (1.69 %) ',\n",
       " '2021-07-28T15:40:18.479628+0200 INFO Size of output data for year 1740 (+5/-5 years): 1274 data sets (1.73 %) ',\n",
       " '2021-07-28T15:40:30.357313+0200 INFO Size of output data for year 1750 (+5/-5 years): 1274 data sets (1.73 %) ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(c2j.config.log, \"r\", encoding=c2j.config.encoding) as f:\n",
    "    log_text = f.read().splitlines()\n",
    "\n",
    "log_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3863351",
   "metadata": {},
   "source": [
    "Note that new content is always appended to the log file and the file is not deleted nor cleared when you start a new conversion process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef2e07",
   "metadata": {},
   "source": [
    "Now let's see which JSON files were produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da145009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_1710.json',\n",
       " 'demo_1720.json',\n",
       " 'demo_1740.json',\n",
       " 'demo_1750.json',\n",
       " 'demo_1730.json',\n",
       " 'demo_1700.json']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(os.path.dirname(OUTPUT_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2932b59",
   "metadata": {},
   "source": [
    "As you can see, the appropriate year was appended to the file name defined in OUTPUT_FILE for each conversion\n",
    "step.\n",
    "\n",
    "How does the content of the JSON files look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27a9f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cnp01287518', {'515': {'a': ['Breslau']}})\n",
      "('cnp01417964', {'515': {'a': ['Altorf']}})\n",
      "('cnp01418304', {'515': {'a': ['Kiel']}})\n",
      "('cnp01289912', {'515': {'a': ['Venedig']}})\n",
      "('cnp01415306', {'515': {'a': ['Halle']}})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(os.path.dirname(OUTPUT_FILE), 'demo_1710.json'), \"r\", encoding=c2j.config.encoding) as f:\n",
    "    d = json.load(f)\n",
    "    \n",
    "for i in list(d.items())[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bd349",
   "metadata": {},
   "source": [
    "Looking at the first 5 entries in the JSON file, you can see that for each data set in the input file (represented by its ID) that fulfills the requirements (i.e., an appropriate date is given in the date column and field types are as defined), a JSON element is created that represents field, subfield and content values.\n",
    "\n",
    "We can check this by looking at the original input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fee7c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['340 01$8ger$a1678-$xa1678u     ### 340 11$8ger$a1678-1750$xa1678a1750 ### '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"] == \"cnp01287518\"][\"340$x\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08577a58",
   "metadata": {},
   "source": [
    "There are two dates available for this data set. The first one is ignored in the conversion process because the date indicator is \"0\" (and we set our configuration to only allow the date indicator \"1\"). However, the second date for this data set has the correct date indicator and -- as can be seen in the subfield \\\\$x -- the person represented in this data set was active between 1678 and 1750. Since the JSON file we looked at was created for the year 1710 and this year is within the 1678--1750 range, the data sets was converted correctly. \n",
    "\n",
    "Moreover, this person should be in ALL our six JSON files created, because all years between 1700 and 1750 are within the activity years of this person. Let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5d3553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_1710.json {'515': {'a': ['Breslau']}}\n",
      "demo_1720.json {'515': {'a': ['Breslau']}}\n",
      "demo_1740.json {'515': {'a': ['Breslau']}}\n",
      "demo_1750.json {'515': {'a': ['Breslau']}}\n",
      "demo_1730.json {'515': {'a': ['Breslau']}}\n",
      "demo_1700.json {'515': {'a': ['Breslau']}}\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(os.path.dirname(OUTPUT_FILE)):\n",
    "    with open(os.path.join(os.path.dirname(OUTPUT_FILE), file), \"r\", encoding=c2j.config.encoding) as f:\n",
    "        d = json.load(f)\n",
    "    print(file, d[\"cnp01287518\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea678f",
   "metadata": {},
   "source": [
    "Indeed, the data for person \"cnp01287518\" is available in all JSON files.\n",
    "\n",
    "So let's check if the person is correctly ignored when our conversion years are not within the 1678--1750 range. To test this, we have to run a new conversion with other configuration options. We can however re-use our previous configuration and just replace the new year parameters. Everything else stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61911898",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2j.config.from_ = 1751\n",
    "c2j.config.to = 1751"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d3354",
   "metadata": {},
   "source": [
    "Running the conversion is as simple as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07e86c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f5b5e425a448f6b84bbbf2bfdadd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c2j.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603f6f4",
   "metadata": {},
   "source": [
    "Again we look at the produced JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78f973ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cnp01414461', {'515': {'a': ['Dannenbüttel']}})\n",
      "('cnp01414528', {'515': {'a': ['Salzwedel']}})\n",
      "('cnp01414634', {'515': {'a': ['Halle', 'Pulsnitz']}})\n",
      "('cnp01415266', {'515': {'a': ['Rodleben', 'Roßlau']}})\n",
      "('cnp02047759', {'515': {'a': ['Coswig']}})\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(os.path.dirname(OUTPUT_FILE), 'demo_1751.json'), \"r\", encoding=c2j.config.encoding) as f:\n",
    "    d = json.load(f)\n",
    "    \n",
    "for i in list(d.items())[:5]:\n",
    "    print(i)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92be67",
   "metadata": {},
   "source": [
    "It seems the conversion was successful. But is person \"cnp01287518\" available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7140b23a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Data set with ID cnp01287518 is not in the data!'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17980/3063384819.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mperson_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cnp01287518\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mperson_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data set with ID {person_id} is not in the data!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Data set with ID cnp01287518 is not in the data!'"
     ]
    }
   ],
   "source": [
    "person_id = \"cnp01287518\"\n",
    "if person_id not in d.keys():\n",
    "    raise KeyError(f\"Data set with ID {person_id} is not in the data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8766558",
   "metadata": {},
   "source": [
    "This shows that the data set with ID \"cnp01287518\" was ignored in the conversion process because the dates given in column \"340\\\\$x\" are not within the years defined in the conversion configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c53f7d7",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
