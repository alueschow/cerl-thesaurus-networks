{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Networks - Full example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents a full example of constructing, analysing and visualising city data from the CERL Thesaurus -- starting from getting the data out of the database to plotting it on a HTML map that can easily be shared.\n",
    "\n",
    "Author: Andreas Lüschow\n",
    "\n",
    "Last updated: 2021/09/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Querying the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we have to import some python modules and packages to work with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # for reading/writing JSON data\n",
    "import os  # for file system manipulation (i.e., creating files etc.)\n",
    "\n",
    "from cerl import ample_query, ample_record, ids_from_result, by_dot, the  # CERL specific python library, see https://pypi.org/project/cerl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of each python script, it's always a good idea to define variables that are used throughout the script. By this, we are able to find and change our parameters easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file path\n",
    "DOWNLOAD_PATH = \"./data/ct.json\"  # data from the CERL Thesaurus will be downloaded into this file\n",
    "\n",
    "# create the directory in the download path if it does not already exist\n",
    "if not os.path.exists(os.path.dirname(DOWNLOAD_PATH)):\n",
    "    os.makedirs(os.path.dirname(DOWNLOAD_PATH))\n",
    "    \n",
    "# the output data    \n",
    "download_data = {}  # a python dictionary that will contain the data we collect    \n",
    "\n",
    "# the database used\n",
    "DATABASE = 'data.cerl.org/thesaurus'\n",
    "\n",
    "# the search query used\n",
    "QUERY = 'related_to:cnl00029316 AND type:cnp'  # i.e., get people records related to Göttingen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to make a connection to the database, send a search query and handle the retrieved data sets afterwards. This may take a minute or two.\n",
    "\n",
    "__As the search query defined above shows, we are interested in people that were active in Göttingen. From these person records we will collect all information about places of activity. We will then construct a network of cities.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the CERL Thesaurus and run the search query\n",
    "result = ample_query(DATABASE, QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the search results\n",
    "for idx in ids_from_result(result):\n",
    "    record = ample_record(DATABASE, idx)  # get the record as a python dictionary\n",
    "    cid = the(by_dot(record, '_id'))  # access the record by dot notation (see https://pypi.org/project/cerl/ for more explanation)\n",
    "    assert cid == idx  # just to make sure the correct record was downloaded\n",
    "\n",
    "    download_data[cid] = {\"515\": {\"a\": []}}  # add information about the record ID, the field and subfield to the output dictionary\n",
    "\n",
    "    # iterate over places in the record\n",
    "    for places in by_dot(record, \"data.place\"):\n",
    "        for place in places:\n",
    "            try:\n",
    "                type_place = place[\"typeOfPlace\"]  # try to get type of place\n",
    "                place_id = place[\"id\"]  # try to get place identifier\n",
    "                \n",
    "                # add combination of place type and ID to output dictionary\n",
    "                if type_place == \"actv\" and place_id is not None:\n",
    "                    download_data[cid][\"515\"][\"a\"].append(place_id)\n",
    "            except:\n",
    "                pass        \n",
    "\n",
    "    # if no place of activity was found, remove empty entries from the output dictionary\n",
    "    if len(download_data[cid][\"515\"][\"a\"]) == 0:\n",
    "        del download_data[cid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the data to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DOWNLOAD_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(download_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a part of the data we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DOWNLOAD_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# show five entries from the data\n",
    "for x in list(data)[:5]:\n",
    "    print(x, data[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Creating an edge list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a graph representation of our data, i.e., a format were nodes and edges are defined. We use the python library _Bibliometa_ to this end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # python library for handling tabular data\n",
    "\n",
    "from bibliometa.graph.conversion import JSON2EdgeList\n",
    "from bibliometa.graph.similarity import Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some paths were our input and output data will be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_PATH = \"./data/similarity.csv\"\n",
    "GRAPH_CORPUS_PATH = \"./data/graph_corpus.json\"\n",
    "LOG_PATH = \"./data/logs/j2e.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bibliometa class `JSON2EdgeList` needs some configuration to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields from the input data that will be considered\n",
    "FIELDS = [(\"515\", \"a\")]\n",
    "\n",
    "# whether keys and values from the input data will be switched\n",
    "# since we downloaded person records but want to create a network of places, we set this parameter to True\n",
    "SWAP = True  \n",
    "\n",
    "# Similarity functions that will be used in graph creation.\n",
    "# Two nodes (i.e., cities) are only considered connected if their similarity is greater then zero.\n",
    "# See the Bibliometa documentation for more information about this.\n",
    "# The following similarity function will consider two cities connected, if they occur together in at least one person record.\n",
    "SIM_FUNCTIONS = [\n",
    "    {\"name\": \"mint_1\",\n",
    "     \"function\": Similarity.Functions.mint,\n",
    "     \"args\": {\n",
    "         \"f\": lambda a, b: len(list(a.intersection(b))),\n",
    "         \"t\": 1}\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run start the JSON to edge list conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j2e = JSON2EdgeList()\n",
    "\n",
    "j2e.set_config(i=DOWNLOAD_PATH,\n",
    "               o=SIMILARITY_PATH,\n",
    "               create_corpus=True,\n",
    "               corpus=GRAPH_CORPUS_PATH,\n",
    "               log=LOG_PATH,\n",
    "               fields=FIELDS,\n",
    "               sim_functions=SIM_FUNCTIONS,\n",
    "               swap=SWAP\n",
    "               )\n",
    "j2e.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edge list looks as follows. Column 1 and 2 contain the name of a node (i.e., place), column 3 contains the number of connections between these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SIMILARITY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    df = pd.read_csv(f, sep=\"\\t\", header=None, index_col=0)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Graph Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the edge list we can run some graph analysis algorithms. This will also create a graph representation in GraphML format which we will user later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bibliometa.graph.analysis import GraphAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_FILE = \"./data/similarity.tar.gz\"\n",
    "OUTPUT_FILE = \"./data/graph_analysis.txt\"\n",
    "IMG_FOLDER = \"./data/img/\"\n",
    "LOG_PATH = \"./data/logs/ga.log\"\n",
    "\n",
    "CREATE_GRAPHML = True\n",
    "GRAPHML_FILE = \"./data/graphml.graphml\"\n",
    "\n",
    "NODES = \"cities\"  # name for nodes\n",
    "EDGES = \"similarity\"  # name for edges\n",
    "SIMILARITY_FUNCTION = \"mint_1\"  # name of similarity function used in graph creation\n",
    "SIMILARITY_FUNCTIONS_ALL = [\"mint_1\"]  # list of available similarity functions (see previous conversion step from JSON to edge list)\n",
    "THRESHOLD = 0  # threshold of similarity function\n",
    "WEIGHTED = True  # whether similarity function is weighted\n",
    "\n",
    "# analyses that will be used\n",
    "TYPES = [\"node_count\",\n",
    "         \"edge_count\",\n",
    "         \"component_count\",\n",
    "         \"max_component\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GraphAnalysis()\n",
    "\n",
    "ga.set_config(i=SIMILARITY_FILE,\n",
    "              o=OUTPUT_FILE,\n",
    "              create_graphml=CREATE_GRAPHML,\n",
    "              graphml=GRAPHML_FILE,\n",
    "              img=IMG_FOLDER,\n",
    "              log=LOG_PATH,\n",
    "              n=NODES,\n",
    "              e=EDGES,\n",
    "              sim=SIMILARITY_FUNCTION,\n",
    "              sim_functions=SIMILARITY_FUNCTIONS_ALL,\n",
    "              t=THRESHOLD,\n",
    "              weighted=WEIGHTED,\n",
    "              types=TYPES\n",
    "              )\n",
    "ga.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Network creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the GraphML file created in the previous step we now can draw a nice network of cities and their connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx  # a library for network modeling and analysis\n",
    "import osmnx as ox  # a library for more beautiful network visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have to decide for which city want to draw the network. Since we downloaded data sets related to Göttingen, it's reasonable to draw a network around Göttingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COORDINATES = \"./data/lng_lat.csv\"  # path to a CSV file with longitude/latitude information \n",
    "KEYS_LABELS = (\"id\", \"city\")  # needed for parsing the coordinates file\n",
    "\n",
    "ego = \"cnl00029316\"  # CERL Thesaurus ID for Göttingen \n",
    "EGO_DEPTH = 1  # degree of neighbor nodes considered in the network\n",
    "EGO_FILE = \"./data/ego.graphml\"  # a network centered around the \"ego\" city\n",
    "HTML_FILE = \"./data/network.html\"  # output HTML representation of the network\n",
    "\n",
    "CRS = \"epsg:4326\"  # coordinate reference system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a bit longer than in the previous steps, so we split it into three parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting position of graph nodes\n",
    "def create_pos(graph, df, keys_labels):\n",
    "    pos = {}\n",
    "    for n in graph.nodes:\n",
    "        lat = df[df[keys_labels] == n][\"lat\"].to_string(index=False)\n",
    "        lng = df[df[keys_labels] == n][\"lng\"].to_string(index=False)\n",
    "        try:\n",
    "            pos[n] = [float(lng), float(lat)]\n",
    "        except:\n",
    "            pos[n] = [None, None]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read GraphML file\n",
    "g = nx.read_graphml(GRAPHML_FILE)\n",
    "\n",
    "# create ego network around ego node\n",
    "g = nx.ego_graph(g, ego, radius=EGO_DEPTH)\n",
    "\n",
    "# read coordinates\n",
    "df = pd.read_csv(COORDINATES, sep=\"\\t\")\n",
    "\n",
    "# create positions for nodes in the ego network\n",
    "pos = create_pos(g, df, KEYS_LABELS[0])\n",
    "\n",
    "# remove nodes without reasonable coordinate information\n",
    "for node, (x, y) in pos.items():\n",
    "    if x and y:\n",
    "        g.nodes[node]['x'] = float(x)\n",
    "        g.nodes[node]['y'] = float(y)\n",
    "    else:\n",
    "        g.remove_node(node)\n",
    "\n",
    "# save ego network as GraphML\n",
    "nx.write_graphml(g, EGO_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MultiDiGraph from ego network\n",
    "G = nx.MultiDiGraph(crs=CRS)\n",
    "for n in g.nodes:\n",
    "    G.add_node(n, x=g.nodes[n][\"x\"], y=g.nodes[n][\"y\"])\n",
    "G.add_edges_from(g.edges)\n",
    "\n",
    "# plot ego network on map and save as HTML\n",
    "m = ox.folium.plot_graph_folium(G, color='#fe7830', weight=1, opacity=0.7)\n",
    "m.save(HTML_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
